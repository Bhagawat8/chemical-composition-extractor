# ğŸ§ª Chemical Composition Extraction from Material Certificates

A document intelligence pipeline that extracts chemical composition data and other information from PDFs using DeepSeek-OCR, a vision-language model optimized for document understanding.

---

## ğŸ“– Introduction

Material certificates are critical documents in manufacturing and supply chain management. They contain chemical composition tables that define the exact elemental makeup of metal alloys like Ti-6Al-4V (Titanium Grade 5). Manually extracting this data is tedious, error-prone, and does not scale.

This project automates the entire extraction process. You give it a PDF, it returns a clean CSV with element symbols, values, units, and metadata. No templates. No manual intervention.

The core challenge was not just OCR, but understanding document structure. Traditional OCR tools like Tesseract can read text, but they cannot understand that "6.53 - 6.54" under "AL" in a table means Aluminum content is in that range. We needed something smarter.

After evaluating multiple approaches including Tesseract with layout analysis and various open-source alternatives, we settled on DeepSeek-OCR. It is a vision-language model that understands documents the way humans do: visually. It outputs structured markdown with tables intact, which makes parsing significantly easier.

---

## ğŸ’» System Requirements

### ğŸ”§ Hardware Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| GPU | 16GB VRAM (T4) | 24GB VRAM (A10G) |
| System RAM | 16GB | 32GB |
| Storage | 20GB free | SSD preferred |

> **âš ï¸ GPU is mandatory.** DeepSeek-OCR is a 7-billion parameter vision-language model. CPU inference takes 10+ minutes per page with vanilla attention algorithm, making it inefficient.

---

### âš¡ Why Flash Attention is Default

We use Flash Attention 2.0 as the default attention mechanism for three reasons:

1. **ğŸ’¾ Memory efficiency**: Flash Attention reduces VRAM usage by 2-4x compared to standard attention, allowing the 7B model to fit on 16GB GPUs
2. **ğŸš€ Speed**: 2-3x faster inference on supported hardware (Ampere architecture and newer)
3. **âœ… No accuracy loss**: Flash Attention is mathematically equivalent to standard attention

> Flash Attention requires CUDA-capable GPU. On unsupported hardware, the model falls back to standard attention but may run out of memory.

---

### ğŸ’° Estimated Processing Cost (A10G GPU)

Based on testing with AWS g5.xlarge instance ($1.006/hour for A10G):

| Metric | Value |
|--------|-------|
| â±ï¸ Time per page | ~12-15 seconds |
| ğŸ“„ Pages per hour | ~240-300 |
| ğŸ’µ Cost per page | ~$0.003-0.004 |
| ğŸ“Š Cost per 100 pages | ~$0.35-0.40 |

> ğŸ“ Model loading takes ~30 seconds on first run. Subsequent pages process faster with cached model.

---

## âœ¨ Core Features and Implementation

### ğŸ”„ What This Pipeline Does

1. ğŸ“¥ Takes any PDF file as input
2. ğŸ–¼ï¸ Converts PDF pages to high-resolution images (400 DPI)
3. ğŸ”ƒ Automatically corrects image orientation using Tesseract OSD
4. ğŸ‘ï¸ Runs DeepSeek-OCR on each images individually to extract text with structure preserved
5. ğŸ”— Merged the OCR extracted text of all images.
6. ğŸ“Š Parses the OCR output to identify chemical composition tables
7. ğŸŒ Handles German number formats (comma as decimal separator) and other irregularity
8. ğŸ“‹ Distinguishes between requirement values and actual test results
9. ğŸ“¤ Exports clean CSV with element data and PDF's metadata

---

### ğŸ¯ Key Technical Decisions

#### ğŸ¤” Why DeepSeek-OCR over Tesseract?

Tesseract is excellent for clean, well-formatted text. But material certificates are messy. They have rotated pages, multi-column layouts, tables with merged cells, and stamps overlapping text. DeepSeek-OCR handles all of this because it processes the document as an image and understands layout contextually.

#### ğŸ”„ Why Tesseract for Orientation Detection?

DeepSeek-OCR expects correctly oriented images. Scanned certificates are often rotated 90 or 270 degrees. Tesseract OSD is fast and reliable for detecting rotation. We use it purely for orientation detection, not for OCR.

#### ğŸ” Why 400 DPI?

We tested 200, 300, and 400 DPI. At 200 DPI, small text became blurry and OCR accuracy dropped. At 400 DPI, we get consistently readable text without excessive file sizes.

#### ğŸŒ Handling German Number Formats

European certificates often use German notation: `0,004` instead of `0.004`. The parser detects comma-period patterns and converts appropriately.

---

## ğŸ“ Project Structure

```
codebase/
    run.py                      # CLI entry point
    requirements.txt            # Python dependencies
    Dockerfile                  # Container configuration
    Submission_notebook.ipynb   # Jupyter notebook for interactive use
    README.md                   # This documentation
    .gitignore                  # Git ignore rules
    src/
        __init__.py             # Package exports
        config.py               # Settings and element lookup
        pdf_io.py               # PDF to image conversion
        ocr_engine.py           # DeepSeek model and inference
        parser.py               # Text parsing and extraction
        export.py               # DataFrame and CSV generation
        main.py                 # Pipeline orchestration
    data/
        input/                  # Place input PDFs here
    diagrams/                   # Flow diagrams
    tests/                      # Unit tests
    output/                     # Generated files
    images/                     # Converted page images
```

---

### ğŸ“ File Descriptions

#### ğŸš€ `run.py`

Command-line entry point. Handles argument parsing and calls the main pipeline.

```bash
python run.py certificate.pdf -o results.csv --dpi 400
```

---

#### ğŸ““ `Submission_notebook.ipynb`

Jupyter notebook version of the pipeline. Useful for:
- ğŸ”§ Interactive development and debugging
- â˜ï¸ Running on cloud platforms (Kaggle, SageMaker, Colab)
- ğŸ“Š Step-by-step execution with visual output
- âš¡ Quick prototyping without CLI setup

The notebook contains the same logic as the Python modules but in cell-by-cell format with inline outputs.

---

#### ğŸ“¦ `requirements.txt`

All Python dependencies grouped by purpose:
- **Core**: torch, transformers
- **PDF**: pdf2image, Pillow
- **OCR**: pytesseract
- **Data**: pandas, numpy
- **Model**: einops, safetensors, accelerate

---

#### âš™ï¸ `src/config.py`

Configuration constants:
- Model name: `deepseek-ai/DeepSeek-OCR`
- DPI: 400 (configurable)
- Image size: 1024 base, 640 inference
- Element lookup table (24 elements)

---

#### ğŸ–¼ï¸ `src/pdf_io.py`

PDF to image conversion with orientation fix:
- Uses pdf2image (Poppler wrapper)
- Tesseract OSD for rotation detection
- Saves as PNG for lossless quality

---

#### ğŸ‘ï¸ `src/ocr_engine.py`

DeepSeek-OCR model management:
- Lazy loading with global cache
- Flash Attention 2.0 enabled
- bfloat16 precision for memory efficiency
- stdout capture for inference results

---

#### ğŸ” `src/parser.py`

Text parsing and value extraction:
- Markdown table detection
- German number conversion
- Value type detection (exact, range, max, less-than)
- Element symbol recognition

---

#### ğŸ“¤ `src/export.py`

Output generation:
- Pandas DataFrame creation
- Column ordering and sorting
- CSV export with metadata

---

#### ğŸ¯ `src/main.py`

Pipeline orchestration:
- Coordinates all modules
- Progress logging
- Error handling
- CLI interface

---

## ğŸ”„ High Level Workflow

```
                    +------------------+
                    |   ğŸ“„ Input PDF   |
                    +--------+---------+
                             |
                             v
                    +------------------+
                    | pdf_to_images()  |
                    | (400 DPI, PNG)   |
                    +--------+---------+
                             |
                             v
                    +------------------+
                    | fix_orientation()|
                    | (Tesseract OSD)  |
                    +--------+---------+
                             |
                             v
                    +------------------+
                    | run_ocr()        |
                    | (DeepSeek-OCR)   |
                    +--------+---------+
                             |
                             v
                    +------------------+
                    | extract_         |
                    | composition()    |
                    +--------+---------+
                             |
                             v
                    +------------------+
                    | create_dataframe |
                    | save_csv()       |
                    +--------+---------+
                             |
                             v
                    +------------------+
                    |  ğŸ“Š Output CSV   |
                    +------------------+
```

> ğŸ’¡ Each step has a single responsibility. If the CSV is wrong, check the parser. If parsing fails, check the OCR. If OCR is garbled, check orientation.

---

## ğŸ› ï¸ Why These Tools

| Tool | Purpose | Why Chosen |
|------|---------|------------|
| ğŸ¤– DeepSeek-OCR | Document OCR | Understands layout, outputs markdown tables |
| âš¡ Flash Attention | Attention mechanism | 2-3x faster, 2-4x less VRAM |
| ğŸ”„ Tesseract OSD | Orientation detection | Fast, accurate, offline |
| ğŸ“„ pdf2image | PDF conversion | Reliable, handles edge cases |
| ğŸ“‘ Poppler | PDF rendering | Industry standard, well-maintained |

---

## âš ï¸ Constraints and Limitations

- **ğŸ–¥ï¸ GPU required**: CPU inference is too slow for practical use
- **ğŸ“„ Single certificate per PDF**: Multi-certificate PDFs merge data incorrectly
- **ğŸ”¤ Latin alphabet**: Element symbols must be in standard notation
- **ğŸ” OCR accuracy**: Values like 0.004 and 0.0004 can be confused on poor prints

---

## ğŸš€ Future Enhancements

- ğŸ“Š Confidence scores for extracted values
- ğŸ“‘ Multi-certificate PDF support
- ğŸ—„ï¸ Batch processing with database output
- ğŸ¯ Fine-tuned model for material certificates

---

## ğŸ“– Usage

### ğŸ“¥ Installation

```bash
# System dependencies
sudo apt-get install poppler-utils tesseract-ocr

# Python dependencies
pip install -r requirements.txt

# Flash Attention (requires GPU)
pip install flash-attn --no-build-isolation
```

---

### ğŸ’» Command Line

```bash
python run.py certificate.pdf
python run.py certificate.pdf -o results.csv
python run.py certificate.pdf --dpi 300
```

---

### ğŸ Python Module

```python
from src import extract_chemical_composition

df = extract_chemical_composition("certificate.pdf")
print(df)
```

---

### ğŸ““ Jupyter Notebook

Open `Submission_notebook.ipynb` and run cells sequentially. The notebook includes installation cells for cloud environments.

---

### ğŸ³ Docker

Build the Docker image:

```bash
docker build -t chemical-composition-extractor .
---

## ğŸ› ï¸ Development Notes

This project started with Tesseract and OpenCV-based table detection. It worked for clean certificates but failed on rotated scans and unusual layouts.

The breakthrough came with vision-language models. DeepSeek-OCR understands documents visually and outputs structured markdown, making parsing straightforward.

> ğŸ’¡ **Key debugging insight**: `model.infer()` prints to stdout instead of returning results. Capturing stdout solved the "None return" problem that consumed hours of debugging.

> ğŸ“ **Lesson learned**: orientation matters more than resolution. A rotated high-res image produces worse OCR than a correctly oriented low-res image.

---

## ğŸ“š References

- ğŸ¤– **DeepSeek-OCR Model**: https://huggingface.co/deepseek-ai/DeepSeek-OCR
- ğŸ“„ **DeepSeek-VL2 Paper**: https://arxiv.org/abs/2412.10302
- âš¡ **Flash Attention Paper**: https://arxiv.org/abs/2205.14135
- ğŸ“– **Transformers Library**: https://huggingface.co/docs/transformers
